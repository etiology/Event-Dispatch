{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Event Dispatcher The Event Source Pattern provides a way for applications to communicate to other systems through a series of events. Each event contains state change data. Downstream services can listen for these events and take action when they are received. The Dispatch class provides a mechanism for subscribing our custom functions to these events. The dispatcher reads events from a source and then propagates them to registered callback functions. graph TD inf1((Kafka)) inf2((SQL)) inf3((ZeroMQ)) inf4((RabbitMQ)) inf5((Redis)) src[Event Source] dis[[Dispatcher]] reg[[Handler Registry]] subgraph Handler Functions h1([Registered Handler1]) h2([Registered Handler2]) h3([Registered Handler3]) end subgraph Event Sources inf1 --> src inf2 --> src inf3 --> src inf4 --> src inf5 --> src end src -->|next event| dis dis --> reg reg -->|callback| h1 reg -->|callback| h2 reg -->|callback| h3","title":"Introduction"},{"location":"#event-dispatcher","text":"The Event Source Pattern provides a way for applications to communicate to other systems through a series of events. Each event contains state change data. Downstream services can listen for these events and take action when they are received. The Dispatch class provides a mechanism for subscribing our custom functions to these events. The dispatcher reads events from a source and then propagates them to registered callback functions. graph TD inf1((Kafka)) inf2((SQL)) inf3((ZeroMQ)) inf4((RabbitMQ)) inf5((Redis)) src[Event Source] dis[[Dispatcher]] reg[[Handler Registry]] subgraph Handler Functions h1([Registered Handler1]) h2([Registered Handler2]) h3([Registered Handler3]) end subgraph Event Sources inf1 --> src inf2 --> src inf3 --> src inf4 --> src inf5 --> src end src -->|next event| dis dis --> reg reg -->|callback| h1 reg -->|callback| h2 reg -->|callback| h3","title":"Event Dispatcher"},{"location":"dispatcher/","text":"Dispatcher The Dispatcher class provides the main runtime for consuming events and distributing them the handler registry. Classes Dispatcher Processes events from a source by passing them to registered event handlers Methods run ( self ) Read events from the source and dispatch them to the handlers Source code in event_stream_processor/domain/entities/dispatch.py def run ( self ) -> None : \"\"\" Read events from the source and dispatch them to the handlers \"\"\" try : logger . info ( \"[STARTING] Event Runner\" ) asyncio . run ( self . _start_processing_events ()) except KeyboardInterrupt : logger . info ( \"[STOPPED] Event Runner\" )","title":"Dispatcher"},{"location":"dispatcher/#dispatcher","text":"The Dispatcher class provides the main runtime for consuming events and distributing them the handler registry.","title":"Dispatcher"},{"location":"dispatcher/#event_stream_processor.domain.entities.dispatch-classes","text":"","title":"Classes"},{"location":"dispatcher/#event_stream_processor.domain.entities.dispatch.Dispatcher","text":"Processes events from a source by passing them to registered event handlers","title":"Dispatcher"},{"location":"dispatcher/#event_stream_processor.domain.entities.dispatch.Dispatcher-methods","text":"","title":"Methods"},{"location":"dispatcher/#event_stream_processor.domain.entities.dispatch.Dispatcher.run","text":"Read events from the source and dispatch them to the handlers Source code in event_stream_processor/domain/entities/dispatch.py def run ( self ) -> None : \"\"\" Read events from the source and dispatch them to the handlers \"\"\" try : logger . info ( \"[STARTING] Event Runner\" ) asyncio . run ( self . _start_processing_events ()) except KeyboardInterrupt : logger . info ( \"[STOPPED] Event Runner\" )","title":"run()"},{"location":"handler_registry/","text":"Handler Registry The HandlerRegistry class provides a mechanism for assigning functions to specific event types. Registered functions will be passed their subscribed events as they occur. The router requires that all functions registered to events be asynchronous. Classes HandlerRegistry Methods and functions can be added to the HandlerRegistry via the register_async_processor decorator. When an event is processed by the router, all of the processors assigned to that event type will be passed the event to process. Examples: Assign events to functions using a decorator: handler_registry = HandlerRegistry() # register `reserve_product_inventory` to the `OrderPlaced` event type @handler_registry.register_async_processor(\"OrderPlaced\") async def reserve_product_inventory(event): # ... # register `create_shipping_order` to the `ReadyToShip` event type @handler_registry.register_async_processor(\"ReadyToShip\") async def create_shipping_order(event): # ... # register `send_customer_shipment_receipt` to the `ItemShipped` event type @handler_registry.register_async_processor(\"ItemShipped\") def send_customer_shipment_receipt(event): # ... Assign events to a method of a class: class MyMerchExample: def __init__(self): # ... perhaps this class needs to be # initialized before handling events ... async def reserve_product_inventory(self, event): ... async def create_shipping_order(self, event): ... async def send_customer_shipment_receipt(self, event): ... merch = MyMerchExample(...) handler_registry = HandlerRegistry() handler_registry.register_async_processor(\"OrderPlaced\", merch.reserve_product_inventory) handler_registry.register_async_processor(\"ReadyToShip\", merch.create_shipping_order) handler_registry.register_async_processor(\"ItemShipped\", merch.send_customer_shipment_receipt) Sending the events to the registered handlers can be done by calling the async_process_event() method and passing in the event to process: # ... send events into the registered handlers for event in event_stream.read(): await handler_registry.async_process_event(event) Attributes is_empty : bool property readonly returns true if the registry is empty Methods async_process_event ( self , event , timeout = 2.0 ) async Run all processors registered to this type of event Parameters: Name Type Description Default event Event The data to pass to the registered event processors required timeout float Maximum time in seconds that an event processor is allowed to run 2.0 Source code in event_stream_processor/domain/entities/handler_registry.py async def async_process_event ( self , event : Event , timeout : float = 2.0 ) -> None : \"\"\"Run all processors registered to this type of event Args: event: The data to pass to the registered event processors timeout: Maximum time in seconds that an event processor is allowed to run \"\"\" logger . info ( f \"Processing - { event } \" ) event_processing_coroutines = [ asyncio . wait_for ( registered_processor ( event ), timeout = timeout ) for registered_processor in self . event_processors [ event . EventType ] ] results = await asyncio . gather ( * event_processing_coroutines , return_exceptions = True ) # Log any failures from the event processors err_results = [ result for result in results if isinstance ( result , Exception )] if err_results : logger . error ( f \"async_process_event - uncaught error from an event processor: { err_results } \" ) register_async_processor ( self , event_type , method = None ) A Decorator that registers an async function for specific even type The event stream consists of message that contain an 'EventType' identifier. This decorator is used to ensure the function is passed these events when they occur in the stream. !!! notes An event processor function needs to accept an Event model as an argument Parameters: Name Type Description Default event_type str case-insensitive event_type that the decorated function will receive required method <built-in function callable> (Optional) Used if the callable being registered is a method on a class None Returns: Type Description <built-in function callable> callable Source code in event_stream_processor/domain/entities/handler_registry.py def register_async_processor ( self , event_type : str , method : callable = None ) -> callable : \"\"\"A Decorator that registers an async function for specific even type The event stream consists of message that contain an 'EventType' identifier. This decorator is used to ensure the function is passed these events when they occur in the stream. Notes: An event processor function needs to accept an Event model as an argument Args: event_type: case-insensitive event_type that the decorated function will receive method: (Optional) Used if the callable being registered is a method on a class Returns: callable \"\"\" if method : self . event_processors [ event_type ] . append ( method ) return else : # when decorating a function def decorated ( fn ): @wraps ( fn ) def wrapper ( * args , ** kwargs ): return fn ( * args , ** kwargs ) with BadProcessorRegistrationError . check_expressions ( \"event processor\" ) as check : check ( inspect . iscoroutinefunction ( fn ), \"needs to be a coroutine\" ), check ( \"event\" in inspect . signature ( fn ) . parameters , \"needs to accept an 'event' as a parameter\" , ) self . event_processors [ event_type ] . append ( fn ) return wrapper return decorated","title":"Registry"},{"location":"handler_registry/#handler-registry","text":"The HandlerRegistry class provides a mechanism for assigning functions to specific event types. Registered functions will be passed their subscribed events as they occur. The router requires that all functions registered to events be asynchronous.","title":"Handler Registry"},{"location":"handler_registry/#event_stream_processor.domain.entities.handler_registry-classes","text":"","title":"Classes"},{"location":"handler_registry/#event_stream_processor.domain.entities.handler_registry.HandlerRegistry","text":"Methods and functions can be added to the HandlerRegistry via the register_async_processor decorator. When an event is processed by the router, all of the processors assigned to that event type will be passed the event to process. Examples: Assign events to functions using a decorator: handler_registry = HandlerRegistry() # register `reserve_product_inventory` to the `OrderPlaced` event type @handler_registry.register_async_processor(\"OrderPlaced\") async def reserve_product_inventory(event): # ... # register `create_shipping_order` to the `ReadyToShip` event type @handler_registry.register_async_processor(\"ReadyToShip\") async def create_shipping_order(event): # ... # register `send_customer_shipment_receipt` to the `ItemShipped` event type @handler_registry.register_async_processor(\"ItemShipped\") def send_customer_shipment_receipt(event): # ... Assign events to a method of a class: class MyMerchExample: def __init__(self): # ... perhaps this class needs to be # initialized before handling events ... async def reserve_product_inventory(self, event): ... async def create_shipping_order(self, event): ... async def send_customer_shipment_receipt(self, event): ... merch = MyMerchExample(...) handler_registry = HandlerRegistry() handler_registry.register_async_processor(\"OrderPlaced\", merch.reserve_product_inventory) handler_registry.register_async_processor(\"ReadyToShip\", merch.create_shipping_order) handler_registry.register_async_processor(\"ItemShipped\", merch.send_customer_shipment_receipt) Sending the events to the registered handlers can be done by calling the async_process_event() method and passing in the event to process: # ... send events into the registered handlers for event in event_stream.read(): await handler_registry.async_process_event(event)","title":"HandlerRegistry"},{"location":"handler_registry/#event_stream_processor.domain.entities.handler_registry.HandlerRegistry-attributes","text":"","title":"Attributes"},{"location":"handler_registry/#event_stream_processor.domain.entities.handler_registry.HandlerRegistry.is_empty","text":"returns true if the registry is empty","title":"is_empty"},{"location":"handler_registry/#event_stream_processor.domain.entities.handler_registry.HandlerRegistry-methods","text":"","title":"Methods"},{"location":"handler_registry/#event_stream_processor.domain.entities.handler_registry.HandlerRegistry.async_process_event","text":"Run all processors registered to this type of event Parameters: Name Type Description Default event Event The data to pass to the registered event processors required timeout float Maximum time in seconds that an event processor is allowed to run 2.0 Source code in event_stream_processor/domain/entities/handler_registry.py async def async_process_event ( self , event : Event , timeout : float = 2.0 ) -> None : \"\"\"Run all processors registered to this type of event Args: event: The data to pass to the registered event processors timeout: Maximum time in seconds that an event processor is allowed to run \"\"\" logger . info ( f \"Processing - { event } \" ) event_processing_coroutines = [ asyncio . wait_for ( registered_processor ( event ), timeout = timeout ) for registered_processor in self . event_processors [ event . EventType ] ] results = await asyncio . gather ( * event_processing_coroutines , return_exceptions = True ) # Log any failures from the event processors err_results = [ result for result in results if isinstance ( result , Exception )] if err_results : logger . error ( f \"async_process_event - uncaught error from an event processor: { err_results } \" )","title":"async_process_event()"},{"location":"handler_registry/#event_stream_processor.domain.entities.handler_registry.HandlerRegistry.register_async_processor","text":"A Decorator that registers an async function for specific even type The event stream consists of message that contain an 'EventType' identifier. This decorator is used to ensure the function is passed these events when they occur in the stream. !!! notes An event processor function needs to accept an Event model as an argument Parameters: Name Type Description Default event_type str case-insensitive event_type that the decorated function will receive required method <built-in function callable> (Optional) Used if the callable being registered is a method on a class None Returns: Type Description <built-in function callable> callable Source code in event_stream_processor/domain/entities/handler_registry.py def register_async_processor ( self , event_type : str , method : callable = None ) -> callable : \"\"\"A Decorator that registers an async function for specific even type The event stream consists of message that contain an 'EventType' identifier. This decorator is used to ensure the function is passed these events when they occur in the stream. Notes: An event processor function needs to accept an Event model as an argument Args: event_type: case-insensitive event_type that the decorated function will receive method: (Optional) Used if the callable being registered is a method on a class Returns: callable \"\"\" if method : self . event_processors [ event_type ] . append ( method ) return else : # when decorating a function def decorated ( fn ): @wraps ( fn ) def wrapper ( * args , ** kwargs ): return fn ( * args , ** kwargs ) with BadProcessorRegistrationError . check_expressions ( \"event processor\" ) as check : check ( inspect . iscoroutinefunction ( fn ), \"needs to be a coroutine\" ), check ( \"event\" in inspect . signature ( fn ) . parameters , \"needs to accept an 'event' as a parameter\" , ) self . event_processors [ event_type ] . append ( fn ) return wrapper return decorated","title":"register_async_processor()"},{"location":"EventSources/event_source_overview/","text":"Event Sources The dispatch system is agnostic to where the event data comes from so long as the source is a subclass of IEventSource . The IEventSource class provides a common interface that is used when dispatching events to handlers. The IEventSource provides setup and teardown mechanics through a context manager. classDiagram class IEventSource { +str cls_name +connect_to_source() +get_event() +close_connection() } class KafkaSource { +KafkaConfig config } class CustomSourceA { +CustomConfig config } class CustomSourceB { +CustomConfig config } class CustomSourceC { +CustomConfig config } IEventSource <|-- KafkaSource IEventSource <|-- CustomSourceA IEventSource <|-- CustomSourceB IEventSource <|-- CustomSourceC Classes IEventSource Interface class to accessing event data Methods close_connection ( self ) clean up any connections to the event source Source code in event_stream_processor/domain/interfaces/event_source.py @abc . abstractmethod def close_connection ( self ) -> None : \"\"\" clean up any connections to the event source \"\"\" ... connect_to_source ( self ) prepare to read events from a source Source code in event_stream_processor/domain/interfaces/event_source.py @abc . abstractmethod def connect_to_source ( self ) -> None : \"\"\" prepare to read events from a source \"\"\" ... get_event ( self ) fetch an event from the source Source code in event_stream_processor/domain/interfaces/event_source.py @abc . abstractmethod def get_event ( self ) -> Optional [ Event ]: \"\"\" fetch an event from the source \"\"\" ...","title":"Overview"},{"location":"EventSources/event_source_overview/#event-sources","text":"The dispatch system is agnostic to where the event data comes from so long as the source is a subclass of IEventSource . The IEventSource class provides a common interface that is used when dispatching events to handlers. The IEventSource provides setup and teardown mechanics through a context manager. classDiagram class IEventSource { +str cls_name +connect_to_source() +get_event() +close_connection() } class KafkaSource { +KafkaConfig config } class CustomSourceA { +CustomConfig config } class CustomSourceB { +CustomConfig config } class CustomSourceC { +CustomConfig config } IEventSource <|-- KafkaSource IEventSource <|-- CustomSourceA IEventSource <|-- CustomSourceB IEventSource <|-- CustomSourceC","title":"Event Sources"},{"location":"EventSources/event_source_overview/#event_stream_processor.domain.interfaces.event_source-classes","text":"","title":"Classes"},{"location":"EventSources/event_source_overview/#event_stream_processor.domain.interfaces.event_source.IEventSource","text":"Interface class to accessing event data","title":"IEventSource"},{"location":"EventSources/event_source_overview/#event_stream_processor.domain.interfaces.event_source.IEventSource-methods","text":"","title":"Methods"},{"location":"EventSources/event_source_overview/#event_stream_processor.domain.interfaces.event_source.IEventSource.close_connection","text":"clean up any connections to the event source Source code in event_stream_processor/domain/interfaces/event_source.py @abc . abstractmethod def close_connection ( self ) -> None : \"\"\" clean up any connections to the event source \"\"\" ...","title":"close_connection()"},{"location":"EventSources/event_source_overview/#event_stream_processor.domain.interfaces.event_source.IEventSource.connect_to_source","text":"prepare to read events from a source Source code in event_stream_processor/domain/interfaces/event_source.py @abc . abstractmethod def connect_to_source ( self ) -> None : \"\"\" prepare to read events from a source \"\"\" ...","title":"connect_to_source()"},{"location":"EventSources/event_source_overview/#event_stream_processor.domain.interfaces.event_source.IEventSource.get_event","text":"fetch an event from the source Source code in event_stream_processor/domain/interfaces/event_source.py @abc . abstractmethod def get_event ( self ) -> Optional [ Event ]: \"\"\" fetch an event from the source \"\"\" ...","title":"get_event()"},{"location":"EventSources/kafka_source/","text":"Kafka Event Source The KafkaEventSource class inherits from IEventSource and provides the dispatcher access to events published to a kafka topic. The source requires a configuration containing connection values to the brokers, their topic, and consumer group, and offset behavior. KafkaConfig is a pyndatic BaseSettings instance which can pull values from environment variables or be explicitly set during instantiation. Classes KafkaConfig pydantic-model Configuration class to setup a KafkaEventSource KafkaEventSource Read events from a kafka topic Methods close_connection ( self ) clean up any connections to the event source Source code in event_stream_processor/infrastructure/kafka_event_source.py def close_connection ( self ) -> None : self . _consumer . close () connect_to_source ( self ) prepare to read events from a source Source code in event_stream_processor/infrastructure/kafka_event_source.py def connect_to_source ( self ) -> None : self . _consumer . subscribe ([ self . configuration . topic_pattern ]) get_event ( self ) read next message Source code in event_stream_processor/infrastructure/kafka_event_source.py def get_event ( self ) -> Optional [ Event ]: \"\"\" read next message \"\"\" try : msg = self . _consumer . poll ( 1.0 ) if msg is None : return None if msg . error (): logger . warning ( \"KafkaEventSource error: {} \" . format ( msg . error ())) return None return Event . parse_raw ( msg . value ()) except pydantic . error_wrappers . ValidationError as err : logger . error ( f \" { self . cls_name } .get_event() deserialization error - { err } \" )","title":"KafkaEventSource"},{"location":"EventSources/kafka_source/#kafka-event-source","text":"The KafkaEventSource class inherits from IEventSource and provides the dispatcher access to events published to a kafka topic. The source requires a configuration containing connection values to the brokers, their topic, and consumer group, and offset behavior. KafkaConfig is a pyndatic BaseSettings instance which can pull values from environment variables or be explicitly set during instantiation.","title":"Kafka Event Source"},{"location":"EventSources/kafka_source/#event_stream_processor.infrastructure.kafka_event_source-classes","text":"","title":"Classes"},{"location":"EventSources/kafka_source/#event_stream_processor.infrastructure.kafka_event_source.KafkaConfig","text":"Configuration class to setup a KafkaEventSource","title":"KafkaConfig"},{"location":"EventSources/kafka_source/#event_stream_processor.infrastructure.kafka_event_source.KafkaEventSource","text":"Read events from a kafka topic","title":"KafkaEventSource"},{"location":"EventSources/kafka_source/#event_stream_processor.infrastructure.kafka_event_source.KafkaEventSource-methods","text":"","title":"Methods"},{"location":"EventSources/kafka_source/#event_stream_processor.infrastructure.kafka_event_source.KafkaEventSource.close_connection","text":"clean up any connections to the event source Source code in event_stream_processor/infrastructure/kafka_event_source.py def close_connection ( self ) -> None : self . _consumer . close ()","title":"close_connection()"},{"location":"EventSources/kafka_source/#event_stream_processor.infrastructure.kafka_event_source.KafkaEventSource.connect_to_source","text":"prepare to read events from a source Source code in event_stream_processor/infrastructure/kafka_event_source.py def connect_to_source ( self ) -> None : self . _consumer . subscribe ([ self . configuration . topic_pattern ])","title":"connect_to_source()"},{"location":"EventSources/kafka_source/#event_stream_processor.infrastructure.kafka_event_source.KafkaEventSource.get_event","text":"read next message Source code in event_stream_processor/infrastructure/kafka_event_source.py def get_event ( self ) -> Optional [ Event ]: \"\"\" read next message \"\"\" try : msg = self . _consumer . poll ( 1.0 ) if msg is None : return None if msg . error (): logger . warning ( \"KafkaEventSource error: {} \" . format ( msg . error ())) return None return Event . parse_raw ( msg . value ()) except pydantic . error_wrappers . ValidationError as err : logger . error ( f \" { self . cls_name } .get_event() deserialization error - { err } \" )","title":"get_event()"}]}